{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "PurpleAnalysis.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPOK00pg02YF0YZREJJeUNl"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xbP8HiYp3hpw"
      },
      "outputs": [],
      "source": [
        "from google.colab import auth\n",
        "auth.authenticate_user()\n",
        "\n",
        "# crowd source data from https://www.google.com/search?q=rgb+color+picker&oq=rgb+color+pick&aqs=chrome.0.0i131i433i512j69i57j0i512l8.3860j0j7&sourceid=chrome&ie=UTF-8 \n",
        "# Spreadsheet: https://docs.google.com/spreadsheets/d/1YxKU56T1j848K0kHcgQfqUuYxjE7G9F2_j87sswKmbE/edit#gid=0\n",
        "\n",
        "import gspread\n",
        "from google.auth import default\n",
        "creds, _ = default()\n",
        "\n",
        "gc = gspread.authorize(creds)\n",
        "\n",
        "worksheet = gc.open('GuessPurple').sheet1\n",
        "\n",
        "# get_all_values gives a list of rows.\n",
        "rows = worksheet.get_all_values()\n",
        "# print(rows)\n",
        "\n",
        "# Convert to a DataFrame and render.\n",
        "import pandas as pd\n",
        "df = pd.DataFrame.from_records(rows)\n",
        "df.columns = df.iloc[0,:]\n",
        "df = df.iloc[1:, :]\n",
        "print(df.head())\n",
        "\n",
        "import numpy as np\n",
        "df[df==''] = np.nan\n",
        "df = df.dropna()\n",
        "\n",
        "df[df==\"No \"] = \"No\" "
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df['R'] = df['R'].astype('float64')\n",
        "df['G'] = df['G'].astype('float64')\n",
        "df['B'] = df['B'].astype('float64')\n",
        "\n",
        "df['PurpleOrNot'] = df['PurpleOrNot'].astype('category')\n",
        "df['Gender'] = df['Gender'].astype('category')\n",
        "df.info()"
      ],
      "metadata": {
        "id": "nl9eoYbp8DcJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.describe()"
      ],
      "metadata": {
        "id": "E1azri1BABEp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.PurpleOrNot.value_counts()"
      ],
      "metadata": {
        "id": "oeDQNHXjABeA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install sweetviz"
      ],
      "metadata": {
        "id": "ERAgJvTg61ii"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install autoviz"
      ],
      "metadata": {
        "id": "1yVCd1s861ZS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install sdv"
      ],
      "metadata": {
        "id": "XmNmWk6e61Hb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Use low-code/no-code libs for EDA"
      ],
      "metadata": {
        "id": "O4c9OdOS7W5h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import sweetviz\n",
        "import pandas as pd\n",
        "my_report = sweetviz.analyze(df)"
      ],
      "metadata": {
        "id": "exZfWsB76p0k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "my_report.show_notebook()"
      ],
      "metadata": {
        "id": "sBOJt3mx9kf2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "my_report.show_html('FinalReport.html')"
      ],
      "metadata": {
        "id": "twzkuVTi6qEb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.to_csv(\"sample.csv\", index=None)"
      ],
      "metadata": {
        "id": "OazkDAeyAF53"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from autoviz.AutoViz_Class import AutoViz_Class\n",
        "AV = AutoViz_Class()\n",
        "df = AV.AutoViz('sample.csv', chart_format = 'html')"
      ],
      "metadata": {
        "id": "ajet9AyC6qNE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.shape"
      ],
      "metadata": {
        "id": "PbAM1i1EAgkX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#How to synthetically oversample the data using gaussian parametric assumptions for a joint probability distribution defined by all the attributes in your dataset"
      ],
      "metadata": {
        "id": "VcIOk2LF765J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sdv.tabular import GaussianCopula\n",
        "model = GaussianCopula()\n",
        "model.fit(df)\n",
        "\n",
        "sample = model.sample(1000)\n",
        "sample.to_csv('sampled_gaussian_jpd.csv')"
      ],
      "metadata": {
        "id": "HJCKOXKT76lR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from autoviz.AutoViz_Class import AutoViz_Class\n",
        "AV = AutoViz_Class()\n",
        "df = AV.AutoViz('sampled_gaussian_jpd.csv', chart_format = 'html')"
      ],
      "metadata": {
        "id": "4fDHamRxAtkn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Model PurpleOrNot as a function of R, G, B and Gender:\n",
        "Evaluate a set of models - not just logistic regression - for the classification ability of Purple, starting with a PORTION of the data for fitting only, but a different portion each time, many times in a row, to see if our model has truly learned something valuable"
      ],
      "metadata": {
        "id": "t-yPkd9ZBOBW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import auth\n",
        "auth.authenticate_user()\n",
        "\n",
        "# crowd source data from https://www.google.com/search?q=rgb+color+picker&oq=rgb+color+pick&aqs=chrome.0.0i131i433i512j69i57j0i512l8.3860j0j7&sourceid=chrome&ie=UTF-8 \n",
        "# Spreadsheet: https://docs.google.com/spreadsheets/d/1YxKU56T1j848K0kHcgQfqUuYxjE7G9F2_j87sswKmbE/edit#gid=0\n",
        "\n",
        "import gspread\n",
        "from google.auth import default\n",
        "creds, _ = default()\n",
        "\n",
        "gc = gspread.authorize(creds)\n",
        "\n",
        "worksheet = gc.open('GuessPurple').sheet1\n",
        "\n",
        "# get_all_values gives a list of rows.\n",
        "rows = worksheet.get_all_values()\n",
        "# print(rows)\n",
        "\n",
        "# Convert to a DataFrame and render.\n",
        "import pandas as pd\n",
        "df = pd.DataFrame.from_records(rows)\n",
        "df.columns = df.iloc[0,:]\n",
        "df = df.iloc[1:, :]\n",
        "print(df.head())\n",
        "\n",
        "import numpy as np\n",
        "df[df==''] = np.nan\n",
        "df = df.dropna()\n",
        "\n",
        "df[df==\"No \"] = \"No\" \n",
        "\n",
        "df['R'] = df['R'].astype('float64')\n",
        "df['G'] = df['G'].astype('float64')\n",
        "df['B'] = df['B'].astype('float64')\n",
        "\n",
        "df['PurpleOrNot'] = df['PurpleOrNot'].astype('category')\n",
        "df['Gender'] = df['Gender'].astype('category')\n",
        "df.info()"
      ],
      "metadata": {
        "id": "UfSdaMfeBTK7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# correlation between test harness and ideal test condition\n",
        "from numpy import mean\n",
        "from numpy import isnan\n",
        "from numpy import asarray\n",
        "from numpy import polyfit\n",
        "from scipy.stats import pearsonr\n",
        "from matplotlib import pyplot\n",
        "from sklearn.datasets import make_classification\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.model_selection import LeaveOneOut\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.linear_model import RidgeClassifier\n",
        "from sklearn.linear_model import SGDClassifier\n",
        "from sklearn.linear_model import PassiveAggressiveClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.tree import ExtraTreeClassifier\n",
        "from sklearn.svm import LinearSVC\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.ensemble import AdaBoostClassifier\n",
        "from sklearn.ensemble import BaggingClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.ensemble import ExtraTreesClassifier\n",
        "from sklearn.gaussian_process import GaussianProcessClassifier\n",
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
        "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
        " \n",
        "# create the dataset\n",
        "def get_dataset(): #n_samples=100):\n",
        "    # X, y = make_classification(n_samples=n_samples, n_features=20, n_informative=15, n_redundant=5, random_state=1)\n",
        "    \n",
        "    X=df[['R', 'G', 'B']]  # Features\n",
        "    y=(df['PurpleOrNot'].astype('str')=='Yes').astype('int') #df['PurpleOrNot'] #.astype('category')  # Labels\n",
        "    \n",
        "    return X, y\n",
        " \n",
        "# get a list of models to evaluate\n",
        "def get_models():\n",
        "    models = list()\n",
        "    models.append(LogisticRegression())\n",
        "    models.append(RidgeClassifier())\n",
        "    models.append(SGDClassifier())\n",
        "    models.append(PassiveAggressiveClassifier())\n",
        "    models.append(KNeighborsClassifier())\n",
        "    models.append(DecisionTreeClassifier())\n",
        "    models.append(ExtraTreeClassifier())\n",
        "    models.append(LinearSVC())\n",
        "    models.append(SVC())\n",
        "    models.append(GaussianNB())\n",
        "    models.append(AdaBoostClassifier())\n",
        "    models.append(BaggingClassifier())\n",
        "    models.append(RandomForestClassifier())\n",
        "    models.append(ExtraTreesClassifier())\n",
        "    models.append(GaussianProcessClassifier())\n",
        "    models.append(GradientBoostingClassifier())\n",
        "    models.append(LinearDiscriminantAnalysis())\n",
        "    models.append(QuadraticDiscriminantAnalysis())\n",
        "    return models\n",
        " \n",
        "# evaluate the model using a given test condition\n",
        "def evaluate_model(cv, model):\n",
        "    # get the dataset\n",
        "    X, y = get_dataset()\n",
        "    # evaluate the model\n",
        "    scores = cross_val_score(model, X, y, scoring='accuracy', cv=cv, n_jobs=-1)\n",
        "    # return scores\n",
        "    return mean(scores)\n",
        " \n",
        "# define test conditions\n",
        "ideal_cv = LeaveOneOut()\n",
        "cv = KFold(n_splits=10, shuffle=True, random_state=1)\n",
        "# get the list of models to consider\n",
        "models = get_models()\n",
        "# collect results\n",
        "ideal_results, cv_results = list(), list()\n",
        "# evaluate each model\n",
        "for model in models:\n",
        "    # evaluate model using each test condition\n",
        "    cv_mean = evaluate_model(cv, model)\n",
        "    ideal_mean = evaluate_model(ideal_cv, model)\n",
        "    # check for invalid results\n",
        "    if isnan(cv_mean) or isnan(ideal_mean):\n",
        "        print(\"skipping\")\n",
        "        continue\n",
        "    # store results\n",
        "    cv_results.append(cv_mean)\n",
        "    ideal_results.append(ideal_mean)\n",
        "    # summarize progress\n",
        "    print('>%s: ideal=%.3f, cv=%.3f' % (type(model).__name__, ideal_mean, cv_mean))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1z1Q9lNEIM-X",
        "outputId": "52871bfa-c20b-4013-97dd-ff9963a393fa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            ">LogisticRegression: ideal=0.639, cv=0.650\n",
            ">RidgeClassifier: ideal=0.638, cv=0.643\n",
            ">SGDClassifier: ideal=0.598, cv=0.560\n",
            ">PassiveAggressiveClassifier: ideal=0.584, cv=0.530\n",
            ">KNeighborsClassifier: ideal=0.607, cv=0.611\n",
            ">DecisionTreeClassifier: ideal=0.574, cv=0.576\n",
            ">ExtraTreeClassifier: ideal=0.584, cv=0.563\n",
            ">LinearSVC: ideal=0.518, cv=0.493\n",
            ">SVC: ideal=0.642, cv=0.648\n",
            ">GaussianNB: ideal=0.621, cv=0.623\n",
            ">AdaBoostClassifier: ideal=0.618, cv=0.629\n",
            ">BaggingClassifier: ideal=0.602, cv=0.611\n",
            ">RandomForestClassifier: ideal=0.616, cv=0.613\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# calculate the correlation between each test condition\n",
        "corr, _ = pearsonr(cv_results, ideal_results)\n",
        "print('Correlation: %.3f' % corr)\n",
        "# scatter plot of results\n",
        "pyplot.scatter(cv_results, ideal_results)\n",
        "# plot the line of best fit\n",
        "coeff, bias = polyfit(cv_results, ideal_results, 1)\n",
        "line = coeff * asarray(cv_results) + bias\n",
        "pyplot.plot(cv_results, line, color='r')\n",
        "# label the plot\n",
        "pyplot.title('10-fold CV vs LOOCV Mean Accuracy')\n",
        "pyplot.xlabel('Mean Accuracy (10-fold CV)')\n",
        "pyplot.ylabel('Mean Accuracy (LOOCV)')\n",
        "# show the plot\n",
        "pyplot.show()"
      ],
      "metadata": {
        "id": "gY8JTIawINEd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rom sklearn.ensemble import ExtraTreesClassifier\n",
        "model = ExtraTreesClassifier()\n",
        "\n",
        "X=df[['R', 'G', 'B']]  # Features\n",
        "y=(df['PurpleOrNot'].astype('str')=='Yes').astype('int') #df['PurpleOrNot'] #.astype('category')  # Labels\n",
        "    \n",
        "from sklearn.model_selection import train_test_split\n",
        "x_train, x_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state = 10)\n",
        "\n",
        "model.fit(x_train,y_train)\n",
        "\n",
        "from sklearn.metrics import classification_report\n",
        "y_pred_proba = model.predict_proba(x_test)[:,1]\n",
        "y_pred = model.predict(x_test)\n",
        "\n",
        "# cr = classification_report(y, y_pred>0.15)\n",
        "cr = classification_report(y_test, y_pred)\n",
        "print(cr)"
      ],
      "metadata": {
        "id": "qWpZEKd1KyMy"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}